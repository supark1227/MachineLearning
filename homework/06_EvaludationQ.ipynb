{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류 및 모델평가 실습과제 - 로지스틱 회귀분석과 동일하게 와인 데이터를 사용\n",
    "- 와인의 화학 조성을 사용하여 와인의 종류를 예측하기 위한 데이터\n",
    "- 독립변수(features): Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline\n",
    "- 종속변수(target): 와인의 종류 0, 1, 2의 세가지 값\n",
    "\n",
    "https://datascienceschool.net/03%20machine%20learning/09.01%20%EB%B6%84%EB%A5%98%EC%9A%A9%20%EC%98%88%EC%A0%9C%20%EB%8D%B0%EC%9D%B4%ED%84%B0.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 불러옵니다.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 읽어오기 및 준비\n",
    "- sklearn.datasets에서 와인 데이터(load_wine)를 읽어온다.\n",
    "- 데이터에 대한 설명을 출력해서 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 178\n",
      ":Number of Attributes: 13 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - Alcohol\n",
      "    - Malic acid\n",
      "    - Ash\n",
      "    - Alcalinity of ash\n",
      "    - Magnesium\n",
      "    - Total phenols\n",
      "    - Flavanoids\n",
      "    - Nonflavanoid phenols\n",
      "    - Proanthocyanins\n",
      "    - Color intensity\n",
      "    - Hue\n",
      "    - OD280/OD315 of diluted wines\n",
      "    - Proline\n",
      "    - class:\n",
      "        - class_0\n",
      "        - class_1\n",
      "        - class_2\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============================= ==== ===== ======= =====\n",
      "                                Min   Max   Mean     SD\n",
      "============================= ==== ===== ======= =====\n",
      "Alcohol:                      11.0  14.8    13.0   0.8\n",
      "Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "Ash:                          1.36  3.23    2.36  0.27\n",
      "Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "Magnesium:                    70.0 162.0    99.7  14.3\n",
      "Total Phenols:                0.98  3.88    2.29  0.63\n",
      "Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "Hue:                          0.48  1.71    0.96  0.23\n",
      "OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "Proline:                       278  1680     746   315\n",
      "============================= ==== ===== ======= =====\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners:\n",
      "\n",
      "Forina, M. et al, PARVUS -\n",
      "An Extendible Package for Data Exploration, Classification and Correlation.\n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "    (1) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "    Comparison of Classifiers in High Dimensional Settings,\n",
      "    Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
      "    Mathematics and Statistics, James Cook University of North Queensland.\n",
      "    (Also submitted to Technometrics).\n",
      "\n",
      "    The data was used with many others for comparing various\n",
      "    classifiers. The classes are separable, though only RDA\n",
      "    has achieved 100% correct classification.\n",
      "    (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
      "    (All results using the leave-one-out technique)\n",
      "\n",
      "    (2) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "    \"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
      "    Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
      "    Mathematics and Statistics, James Cook University of North Queensland.\n",
      "    (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- feature_names에 독립변수의 이름을 저장한다.\n",
    "- data, target의 shape와 feature_names를 출력한다.\n",
    "- data의 첫 5건의 값을 출력한다.\n",
    "- target의 첫 5건의 값을 출력한다.\n",
    "- **`wine.data`와 `wine.target`을 그대로 사용하는 것에 유의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13) (178,)\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# pandas를 사용하고 싶은 경우 아래 코드를 이용\n",
    "#df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "#df[\"target\"] = wine.target\n",
    "feature_names = wine.feature_names\n",
    "print(wine.data.shape, wine.target.shape)\n",
    "print(feature_names)\n",
    "print(wine.data[:5]) \n",
    "print(wine.target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터셋 분리\n",
    "- train_test_split을 이용하여 train set과 test set으로 분리한다.\n",
    "- X_train, X_test, Y_train, Y_test으로 이름을 지정한다.\n",
    "- test_size의 비율은 0.2, random_state는 2024를 설정한다.\n",
    "- 분리된 data set(X_train, X_test, Y_train, Y_test)의 크기를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (142,)\n",
      "(36, 13) (36,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, random_state=2024, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. k-최근접 이웃 학습 및 평가\n",
    "- `KNeighborsClassifier`를 사용\n",
    "- `n_neighbors`를 3으로 설정\n",
    "\n",
    "**출력 예시**\n",
    "```\n",
    "K-neighbor train set score: 0.880\n",
    "K-neighbor test set score: 0.667\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 결정트리(Decision Tree) 학습 및 평가\n",
    "- `DecisionTreeClassifier`를 사용\n",
    "- `random_state`를 7로 설정\n",
    "\n",
    "**출력 예시**\n",
    "```\n",
    "Decision Tree train set score: 1.000\n",
    "Decision Tree test set score: 0.778\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 랜덤 포레스트 (Random Forest) 학습 및 평가\n",
    "- `RandomForestClassifier`를 사용\n",
    "- `n_estimators`를 50으로, `random_state`를 7로 설정\n",
    "\n",
    "**출력 예시**\n",
    "```\n",
    "Random Forest train set score: 1.000\n",
    "Random Forest test set score: 1.000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 서포트 벡터 머신에 스케일링을 적용하고 학습 및 평가\n",
    "- `MinMaxScaler`를 이용해 데이터를 스케일링해서 `X_train_scaled`와 `X_test_scaled`에 저장\n",
    "- `svm.SVC`를 사용\n",
    "- `gamma`를 `auto`로 설정\n",
    "\n",
    "**출력 예시**\n",
    "```\n",
    "Scaled test set accuracy: 1.000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 로지스틱 회귀분석 모형에 교차검증 적용\n",
    "- `LogisticRegression`을 사용\n",
    "- `max_iter`를 10000으로 설정\n",
    "- `KFold`를 사용하고 `n_splits`는 5로, `shuffle`은 하는 것으로, `random_state`는 0으로 설정\n",
    "- `cross_val_score`를 이용해 5개 split에 대한 평가 결과를 계산하고 출력\n",
    "\n",
    "**출력 예시**\n",
    "```\n",
    "Cross-validation scores:\n",
    "[0.97222222 0.91666667 0.97222222 0.97142857 0.94285714]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 검증 데이터 집합(Validation data Set)을 이용해 그리드 서치 실행\n",
    "- wine.data와 wine.target을 train, valid, test의 세 집합으로 분리 (`train_test_split`)\n",
    "- gamma와 C를 각각 [0.001, 0.01, 0.1, 1, 10, 100]에 대해 그리드 서치 실행\n",
    "- 검증 데이터 집합으로 스코어를 계산하고, 이를 이용해 최적 파라미터를 탐색\n",
    "- 최대 스코어와 이 때의 최적 파라미터를 출력\n",
    "- train + valid 데이터 집합으로 다시 학습을 하고 test 데이터 집합에 대해 최종 일반화 성능을 평가해서 출력\n",
    "\n",
    "**출력 예시**\n",
    "```\n",
    "Best score on validation set: 0.79\n",
    "Best parameters:  {'C': 10, 'gamma': 0.001}\n",
    "Test set score with best parameters: 0.84\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
